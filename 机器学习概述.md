机器学习概述
===========


### 概念
机器学习，即让机器模拟或实现人的学习行为，以获取新的知识或技能。它是人工智能的核心，是使计算机具有智能的根本途径。


### 发展历程
```
- 20 世纪
    - 50 年代
        - 初期
            - 推理期
            - 相关研究 - 阿瑟·萨缪尔研制的西洋跳棋程序
        - 中后期
            - 基于神经网络的“连结主义”
    - 60-70 年代
        - 符号主义（基于逻辑表示）
        - 基于决策理论
        - 强化学习技术
        - 统计学习理论的一些奠基性成果
    - 80-90 年代
        - 学习方式分类
            - 机械学习
            - 示教学习
            - 类比学习
            - 归纳学习
        - 从样例中学习
            - 符号主义 （决策树）/ 基于逻辑的学习 （归纳逻辑程序设计）
            - 基于神经网络的连结主义 （BP算法）
    - 90 年代中叶
        - 统计学习 （支持向量机 / 核方法）
- 21 世纪
    - 深度学习
```

### 分类
1. 监督学习   
利用已知分类的样本进行学习

2. 非监督学习   
无需标记样本，让计算机自己学习怎样做

3. 半监督学习   
监督 + 非监督 的结合

4. 强化学习


### 模型
```
    机器学习 = 数据 + 模型 + 优化方法
```

### 损失函数
参考：[机器学习-损失函数 | D.W's Notes - Machine Learning](https://www.csuldw.com/2016/03/26/2016-03-26-loss-function/)


### 优化方法
梯度下降，参考：[浅显易懂！「高中数学」读懂梯度下降的数学原理](https://www.jiqizhixin.com/articles/2019-04-07-6)


### 评价指标
参考：[机器学习评价指标_刘明的博客-CSDN博客](https://blog.csdn.net/fisherming/article/details/80209182)


### 模型选择
1. 交叉验证   
所有数据分为三部分：训练集、交叉验证集和测试集。交叉验证集不仅在选择模型时有用，在超参数选择、正则项参数 [公式] 和评价模型中也很有用。

2. k-折叠交叉验证   
```
    假设训练集为 S ，将训练集等分为 k 份: ${S_1, S_2, ..., S_k}$.
    然后每次从集合中拿出 k-1 份进行训练
    利用集合中剩下的那一份来进行测试并计算损失值
    最后得到 k 次测试得到的损失值，并选择平均损失值最小的模型
```

3. Bias 与 Variance，欠拟合与过拟合    
欠拟合一般表示模型对数据的表现能力不足，通常是模型的复杂度不够，并且 Bias 高，训练集的损失值高，测试集的损失值也高。   
过拟合一般表示模型对数据的表现能力过好，通常是模型的复杂度过高，并且 Variance 高，训练集的损失值低，测试集的损失值高。   

4. 解决方法
```
    增加训练样本: 解决高 Variance 情况
    减少特征维数: 解决高 Variance 情况
    增加特征维数: 解决高 Bias 情况
    增加模型复杂度: 解决高 Bias 情况
    减小模型复杂度: 解决高 Variance 情况
```

### 参数调优
1. 网格搜索   
一种调参手段；穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果

2. 随机搜索   
与网格搜索相比，随机搜索并未尝试所有参数值，而是从指定的分布中采样固定数量的参数设置。它的理论依据是，如果随即样本点集足够大，那么也可以找到全局的最大或最小值，或它们的近似值。通过对搜索范围的随机取样，随机搜索一般会比网格搜索要快一些。

3. 贝叶斯优化算法   
贝叶斯优化用于机器学习调参由 J. Snoek(2012) 提出，主要思想是，给定优化的目标函数(广义的函数，只需指定输入和输出即可，无需知道内部结构以及数学性质)，通过不断地添加样本点来更新目标函数的后验分布(高斯过程,直到后验分布基本贴合于真实分布。简单的说，就是考虑了上一次参数的信息，从而更好的调整当前的参数。


### 参考
1. [team-learning/Task1_ml_overvirew.md at master · datawhalechina/team-learning](https://github.com/datawhalechina/team-learning/blob/master/%E5%88%9D%E7%BA%A7%E7%AE%97%E6%B3%95%E6%A2%B3%E7%90%86/Task1_ml_overvirew.md)
