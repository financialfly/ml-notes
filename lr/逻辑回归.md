逻辑回归
--------


## 逻辑回归与线性回归

二者的原理是相似的，线性回归损失函数为最小二乘法：(y - wx) ^ 2，可以简单描述为这样的过程：   

1. 找一个合适的预测函数，一般表示为 h 函数，该函数就是我们需要着的分类函数，它用来预测输入数据的判断结果。这个过程是非常关键的，需要对数据有一定的了解或分析，知道或者猜测预测函数的大概形式，比如是线性函数还是非线性函数。   
```
    h: f(x1, x2, ... xn) = x1*w1 + x2*w2 + ... + xn*wn + b
```

2. 构造一个 cost 函数，该函数表示预测的输出（h）与训练数据类别（y）之间的偏差，可以是二者之间的差（h-y）或者是其它形式。综合考虑所有训练数据的损失，将 cost 求和或者平均，记为 J(θ) 函数，表示所有训练数据预测值与实际类别的偏差。
```
    cost = (h-y)**2
```

3. 显然，J(θ) 函数的值越小表示预测函数越准确（即 h 函数越准确），所以这一步需要做的是找到 J(θ) 函数的最小值。找函数的最小值有不同的方法，逻辑回归实现时有梯度下降法。


## 原理

### 黑球与白球
假如有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。我 们想知道罐中白球和黑球的比例，但我们不能把罐中的球全部拿出来数。现在我们可以每次任意从已经摇匀的罐中拿一个球出来，记录球的颜色，然后把拿出来的球 再放回罐中。这个过程可以重复，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少？很多人马上就有答案了：70%(这就是与我们最上面所说模型与观察到的数据最吻合的原则)。而其后的理论支撑是什么呢？

参考自：[最大似然估计(Maximum likelihood estimation) | Wenpeng Yin's Blog](https://yinwenpeng.wordpress.com/2013/09/26/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1maximum-likelihood-estimation/)

理论：
```
设白球为 p，黑球为 1-p

取来一个球，白球概率为：
    p

取两个球，都是白球的概率为：
    p ** 2

取了 100 次，30 次是黑球，70 次是白球的概率为：
    p ** 70 * (1-p) ** 30


求导，另其导数为 0，则可以求出最大值时 p 的值，即：
    70 * p ** 69 * (1-p) ** 30 + p ** 70 * 30 * (1-p) ** 29 * (-1) = 0
  -> 70 * (1-p) - p * 30 = 0
  -> 70 - 100p = 0
  -> p = 70%
    
```

### 方程推导

逻辑回归虽然名字里带“回归”，但它实际上是一种分类方法，用于两分类问题（现在经过改进的逻辑回归也可用于多分类）。首先需要找到一个预测函数（h），显然，该函数的输出必须是两类值（分别代表两个类别），所以利用了 Logistic 函数（或称为 Sigmoid 函数），函数形式为：   

\begin{equation}
\sigma(z)=\frac{1}{1+\mathrm{e}^{-z}}
\end{equation}

其中：

$-z$ 即 h: f(x) = x1*w1 + x2*w2 + ... + xn*wn + b

预测函数可以写为：   

\begin{equation}
h_{\theta}(x)=g\left(\theta^{T} x\right)=\frac{1}{1+e^{-\theta^{T} x}}
\end{equation}

其中：
    
$-\theta^{T} x$ 即 w*x，θ^T 即系数 w

cost 函数和 J(θ) 函数是基于最大似然（概率最大）估计推导得到的。   
每个样本属于其真是标记的概率，即似然函数，可以写成：

\begin{equation}
P(y | x ; \theta)=\left(h_{\theta}(x)\right)^{y}\left(1-h_{\theta}(x)\right)^{1-y}
\end{equation}

解释：
    - 令 y 为 0，那么方程为：1-h(x)，令 y 为 1，那么方程为：h(x)，也即白球黑球中的 p 与 1-p，因此该方程可以看作是两个方程的合体。
    
所有样本都属于其真是标记的概率为：
![](https://render.githubusercontent.com/render/math?math=L%28%5Ctheta%29%20%3D%20%5Cprod%5E%7Bm%7D_%7Bi%3D1%7Dh_%5Ctheta%20%28x%5E%7B%28i%29%7D%29%5E%7By%5E%7B%28i%29%7D%7D%20%281-h_%5Ctheta%20%28x%5E%7B%28i%29%7D%29%5E%7B%281-y%5E%7B%28i%29%7D%29%7D&mode=display)

对数似然函数为：
![](https://render.githubusercontent.com/render/math?math=l%28%5Ctheta%29%20%3D%20log%20L%28%5Ctheta%29%20%3D%20%5Csum%5E%7Bm%7D_%7Bi%3D1%7D%20y%5E%7B%28i%29%7Dlog%20h_%5Ctheta%20%28x%5E%7B%28i%29%7D%29%20%2B%20%281-y%5E%7B%28i%29%7D%29log%20%281-h_%5Ctheta%20%28x%5E%7B%28i%29%7D%29%29&mode=display)

最大似然估计就是要求使得 l(θ) 取最大值时的 θ，其实这里可以使用日度上升方法求解，求得的 θ 就是要求的最佳参数。

tips:
```
    以上公式涉及累乘与累加的转化，其原理大概可以描述为：
        假设 a = 10**3 * 10**5 * 10**6
        那么 np.log10(a) = np.log10(10**3) + np.log10(10**5) + np.log10(10**6)
```

## 正则化与模型评估指标

### 正则化

我们可以在损失函数后面，加上正则化函数，即$\theta$的惩罚项，来抑制过拟合问题。

1. L1正则   
$$
J(\theta) =\frac{1}{m}\sum^{m}_{i=1} y^{(i)}h_\theta (x^{(i)}) + (1-y^{(i)})(1-h_\theta (x^{(i)})) + \frac{\lambda}{m
}\sum^m_{i=1}|\theta_i|
$$

$$
\Delta_{\theta_i} l(\theta) = \frac{1}{m}\sum^m_{i=1}(y^{(i)} - h_\theta (x^{(i)}))x^{(i)} + \frac{\lambda}{m}sgn(\theta_i)
$$

梯度下降法的迭代函数变为：
$$\theta:=\theta-K'(\theta)-\frac{\lambda}{m}sgn(\theta)$$


$K(\theta)$为原来的损失函数，由于最后一项的符号由$\theta$决定，可以看到，当$\theta$大于零时，更新后的$\theta$变小；当$\theta$小于零时，更新后的$\theta$变大。因此，L1正则化调整后的结果会更加稀疏（结果向量中有更多的0值）。（见图示，相当于在等高线上找令菱形最小的点。）

![](https://raw.githubusercontent.com/datawhalechina/team-learning/6fb859b4a6efbf0d1727683fbc5d2895482f4225/%E5%88%9D%E7%BA%A7%E7%AE%97%E6%B3%95%E6%A2%B3%E7%90%86/1.png)

2. L2正则

$$
J(\theta) =\frac{1}{m}\sum^{m}_{i=1} y^{(i)}h_\theta (x^{(i)}) + (1-y^{(i)})(1-h_\theta (x^{(i)})) + \frac{\lambda}{2m}\sum^m_{i=1}\theta_i^2
$$

$$
\Delta_{\theta_i} l(\theta) = \frac{1}{m}\sum^m_{i=1}(y^{(i)} - h_\theta (x^{(i)}))x^{(i)} + \frac{\lambda}{m}\theta_i
$$

梯度下降法的迭代函数变为：

$$\theta:=\theta-K'(\theta)-\frac{2\lambda}{m}\theta$$


$K(\theta)$为原来的损失函数，最有一项的$\lambda$决定了对参数的惩罚力度，惩罚力度越大，最后的结果向量的参数普遍较小且分散，避免了个别参数对整个函数起较大的影响。（见图示，相当于在等高线上找令圆形最小的点）

![](https://raw.githubusercontent.com/datawhalechina/team-learning/6fb859b4a6efbf0d1727683fbc5d2895482f4225/%E5%88%9D%E7%BA%A7%E7%AE%97%E6%B3%95%E6%A2%B3%E7%90%86/2.png)

### 逻辑回归的评价指标
参考：[分类之性能评估指标 | D.W's Notes - Machine Learning](http://www.csuldw.com/2016/03/12/2016-03-12-performance-evaluation/)


## sklearn.LogisticRegression 参数

1. 初始化函数
```py
LogisticRegression(penalty='l2',dual=False,tol=1e4,C=1.0,fit_intercept=True,intercept_scaling=1,class_weight=None,random_state=None,solver='liblinear',max_iter=100,multi_class='ovr',verbose=0,warm_start=False, n_jobs=1
    )
```

2. 参数

    `penalty`
        字符串型， l1 or l2，默认：l2；正则化类型。
    `dual`
        布尔型，默认：False。当样本数 > 特征数时，令 dual=False；用于 liblinear 解决器中 L2 正则化。
    `tol`
        浮点型，默认：1e-4；迭代终止判断的误差范围。
    `C`
        浮点型，默认：1.0；其值等于正则化强度的倒数，为正的浮点数。数值越小表示正则化越强。
    `fit_intercept`
        布尔型，默认：True；指定是否应该向决策函数添加常量(即偏差或截距)。
    `intercept_scaling`
        浮点型，默认为 1；仅仅当 solver 是  'liblinear' 时有用。
    `class_weight`
        默认为 None；与 "{class_label: weight}" 形式中的类相关联的权重。如果不给，则所有的类的权重都应该是 1。
        如果类别不均衡，可指定，如 A 类含 100个，B 类含 200个，可指定为：`class_weight={A:2, B:1}` 使其平衡
    `random_state`
        整型，默认 None；当 “solver”==“sag” 或 “liblinear” 时使用。
        在变换数据时使用的伪随机数生成器的种子。
        如果是整数, `random_state`为随机数生成器使用的种子；
        若为 `RandomState` 实例，则 `random_state` 为随机数生成器;
        如果没有，随机数生成器就是 `np.random` 使用的 `RandomState` 实例。
    `solver`
        {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}，默认: 'liblinear'；用于优化问题的算法。
        对于小数据集来说，“liblinear”是个不错的选择，而 'sag' 和 'saga' 对于大型数据集会更快。
        对于多类问题，只有 'newton-cg'， 'sag'， 'saga' 和 'lbfgs' 可以处理多项损失; "liblinear" 仅限于 "one-versus-rest" 分类。
    `max_iter`
        最大迭代次数，整型，默认是 100；
    `multi_class`
        字符串型，{ovr'， 'multinomial'}，默认：'ovr'；
        如果选择的选项是 "ovr"，那么一个二进制问题适合于每个标签，
        否则损失最小化就是整个概率分布的多项式损失。对 liblinear solver 无效。
    `verbose`
        整型，默认是 0；对于 liblinear 和 lbfgs solver，verbose 可以设为任意正数。
    `warm_start`
        布尔型，默认为 False；当设置为 True 时，重用前一个调用的解决方案以适合初始化。
        否则，只擦除前一个解决方案。对 liblinear 解码器无效。
    `n_jobs`
        整型，默认是 1；
        如果 `multi_class='ovr'`，则为在类上并行时使用的 CPU 核数。
        无论是否指定了 `multi_class`，当将 `solver` 设置为 'liblinear' 时，将忽略此参数。如果给定值为 -1，则使用所有核。


## 使用 sklearn
```py
import numpy as np

# 逻辑斯蒂回归在线性模块下
# 和线性回归类似，最终会产生线性方程
# 不同：
#     线性回归解决回归问题
#     逻辑斯蒂回归解决分类问题
#
# 所有的分类问题都是概率问题 KNN 也是一个概率问题
# 线性方程 -> 使用逻辑斯蒂函数将线性方程转化为概率问题 范围为 0~1 -> 概率问题 
import sklearn.datasets as datasets

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split


# 加载数据
iris = datasets.load_iris()

# 4 个属性：花萼长宽，花瓣长宽
X = iris['data']
y = iris['target']

X_train, X_test, y_train, y_test = train_test_split(X, y)

lg = LogisticRegression()
lg.fit(X_train, y_train)

y_ = lg.predict(X_test)
lg.score(X_test, y_test)


# 斜率和截距
# 截距有 3 个，因为该数据是三分类问题，
# 而逻辑回归本质上仍然使用的是二分类问题，
# 使得单一分类与其它两个分类分开 成为二分类问题
# 比如 对三个分类： A, B, C
# 可分为： A，(B, C) / (A, B), C / (A, C), B
lg.coef_, lg.intercept_
```

## team-learning 代码实现
1. 先尝试调用sklearn的线性回归模型训练数据，尝试以下代码，画图查看分类的结果
```py
from __future__ import print_function

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.linear_model import LogisticRegression

%matplotlib inline


df_X = pd.read_csv('./logistic_x.txt', sep='\ +',header=None, engine='python') #读取X值
ys = pd.read_csv('./logistic_y.txt', sep='\ +',header=None, engine='python') #读取y值
ys = ys.astype(int)
df_X['label'] = ys[0].values #将X按照y值的结果一一打标签

ax = plt.axes()
#在二维图中描绘X点所处位置，直观查看数据点的分布情况
df_X.query('label == 0').plot.scatter(x=0, y=1, ax=ax, color='blue')
df_X.query('label == 1').plot.scatter(x=0, y=1, ax=ax, color='red')


#提取用于学习的数据
Xs = df_X[[0, 1]].values
Xs = np.hstack([np.ones((Xs.shape[0], 1)), Xs]) 
ys = df_X['label'].values


lr = LogisticRegression(fit_intercept=False) #因为前面已经将截距项的值合并到变量中，此处参数设置不需要截距项
lr.fit(Xs, ys) #拟合
score = lr.score(Xs, ys) #结果评价
print("Coefficient: %s" % lr.coef_)
print("Score: %s" % score)


ax = plt.axes()

df_X.query('label == 0').plot.scatter(x=0, y=1, ax=ax, color='blue')
df_X.query('label == 1').plot.scatter(x=0, y=1, ax=ax, color='red')

_xs = np.array([np.min(Xs[:,1]), np.max(Xs[:,1])])

#将数据以二维图形式描点，并用学习得出的参数结果作为阈值，划分数据区域
_ys = (lr.coef_[0][0] + lr.coef_[0][1] * _xs) / (- lr.coef_[0][2])
plt.plot(_xs, _ys, lw=1)
```

2. 用梯度下降法将相同的数据分类，画图和sklearn的结果相比较
```py
class LGR_GD():
    
    def __init__(self):
        self.w = None 
        self.n_iters = None
    
    def fit(self,X,y,alpha=0.03,loss = 1e-10): # 设定步长为0.002，判断是否收敛的条件为1e-10
        #重塑y值的维度以便矩阵运算
        y = y.reshape(-1,1) 
        #自变量的维度
        [m,d] = np.shape(X) 
        #将参数的初始值定为0
        self.w = np.zeros((1,d)) 
        tol = 1e5
        self.n_iters = 0

        while tol > loss: #设置收敛条件
            #计算Sigmoid函数结果
            sig = 1/(1+np.exp(-X.dot(self.w.T)))
            
            #迭代theta的值
            theta=self.w + alpha*np.mean(X*(y - sig),axis=0)
            
            #计算损失值
            tol = np.sum(np.abs(theta - self.w))
            self.w = theta
            self.n_iters += 1 #更新迭代次数
    
    def predict(self, X):
        # 用已经拟合的参数值预测新自变量
        y_pred = X.dot(self.w)
        return y_pred  

if __name__ == "__main__":
    lr_gd = LGR_GD()
    lr_gd.fit(Xs,ys)

    ax = plt.axes()

    df_X.query('label == 0').plot.scatter(x=0, y=1, ax=ax, color='blue')
    df_X.query('label == 1').plot.scatter(x=0, y=1, ax=ax, color='red')

    _xs = np.array([np.min(Xs[:,1]), np.max(Xs[:,1])])
    _ys = (lr_gd.w[0][0] + lr_gd.w[0][1] * _xs) / (- lr_gd.w[0][2])
    plt.plot(_xs, _ys, lw=1)
```

3. 用牛顿法实现结果，画图和sklearn的结果相比较，并比较牛顿法和梯度下降法迭代收敛的次数
```py
class LGR_NT():
    
    def __init__(self):
        self.w = None
        self.n_iters = None
    
    def fit(self,X,y,loss = 1e-10): # 判断是否收敛的条件为1e-10
        y = y.reshape(-1,1) #重塑y值的维度以便矩阵运算
        [m,d] = np.shape(X) #自变量的维度
        self.w = np.zeros((1,d)) #将参数的初始值定为0
        tol = 1e5
        n_iters =0
        Hessian = np.zeros((d,d))

        while tol > loss:
            #计算Sigmoid函数结果
            sig = 1/(1+np.exp(-X.dot(self.w.T)))
            grad = np.mean(X*(y - sig),axis=0)
        
            for i in range(d):
                for j in range(d):
                    if j >= i:
                        Hessian[i][j] = np.mean(sig*(sig-1)*X[:,i]*X[:,j]) 
                    else:
                        Hessian[i][j] = Hessian[j][i] 
        
            theta = self.w - np.linalg.inv(Hessian).dot(grad)
            tol = np.sum(np.abs(theta - self.w))
            self.w = theta
            n_iters += 1
        
        self.w = theta
        self.n_iters = n_iters
        
    def predict(self, X):
        # 用已经拟合的参数值预测新自变量
        y_pred = X.dot(self.w)
        return y_pred  

if __name__ == "__main__":
    lgr_nt = LGR_NT()
    lgr_nt.fit(Xs,ys)
```

比较梯度下降法和牛顿法收敛速度
```py
print("梯度下降法结果参数：%s;梯度下降法迭代次数：%s" %(lgr_gd.w,lgr_gd.n_iters))
print("牛顿法结果参数：%s;牛顿法迭代次数：%s" %(lgr_nt.w,lgr_nt.n_iters))
```

## 参考
1. [team-learning/Task3_logistic_regression.ipynb](https://github.com/datawhalechina/team-learning/blob/master/%E5%88%9D%E7%BA%A7%E7%AE%97%E6%B3%95%E6%A2%B3%E7%90%86/Task3_logistic_regression.ipynb)
2. [GitHub - lawlite19/MachineLearning_Python: 机器学习算法python实现](https://github.com/lawlite19/MachineLearning_Python#%E4%BA%8C%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92)
