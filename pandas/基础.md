pandas 基础
------------------

#### Reference

1. [第二章 pandas基础 — Joyful Pandas 1.0 documentation](https://datawhalechina.github.io/joyful-pandas/build/html/%E7%9B%AE%E5%BD%95/ch2.html)

#### 练习

```python
# ---------------
#  口袋妖怪数据集 
# ---------------

# df
"""
   #       Name Type 1  Type 2  Total  HP .. Sp. Atk  Sp. Def  Speed
0  1  Bulbasaur  Grass  Poison    318  45 .. 65       65     45
1  2    Ivysaur  Grass  Poison    405  60 .. 80       80     60
2  3   Venusaur  Grass  Poison    525  80 .. 100      100     80
...
"""

# 对 HP, Attack, Defense, Sp. Atk, Sp. Def, Speed 进行加总，验证是否为 Total 值
df[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']].sum(1)!=df['Total']


# 对于 # 重复的妖怪只保留第一条记录
df_dup = df.drop_duplicates('#', keep='first')

# 第一属性的种类数量
dp_dup['Type 1'].nunique()

# 前三多数量对应的种类
dp_dup['Type 1'].value_counts().index[:3]

# 第一属性和第二属性的组合种类
attr_dup = dp_dup.drop_duplicates(['Type 1', 'Type 2'])

# 尚未出现过的属性组合
L_full = [i+' '+j for i in df['Type 1'].unique() for j in (df['Type 1'].unique().tolist() + [''])]
L_part = [i+' '+j for i, j in zip(df['Type 1'], df['Type 2'].replace(np.nan, ''))]

res = set(L_full).difference(set(L_part))


# 取出物攻，超过120的替换为 high ，不足50的替换为 low ，否则设为 mid
df['Attack'].mask(df['Attack']>120, 'high').mask(df['Attack']<50, 'low').mask((50<=df['Attack'])&(df['Attack']<=120), 'mid').head()

# 取出第一属性，分别用 replace 和 apply 替换所有字母为大写
# replace
df['Type 1'].replace({i:i.upper() for i in df['Type 1'].unique()}).head()
# apply
df['Type 1'].apply(lambda x:x.upper()).head()

# 求每个妖怪六项能力的离差，即所有能力中偏离中位数最大的值，添加到 df 并从大到小排序
df['Deviation'] = df[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']].apply(lambda x:np.max((x-x.median()).abs()), 1)
df.sort_values('Deviation', ascending=False)



# ----------------
# 指数加权窗口
# ----------------

# 作为扩张窗口的 ewm 窗口
np.random.seed(0)
s = pd.Series(np.random.randint(-1,2,30).cumsum())
s.ewm(alpha=0.2).mean()

def ewm_func(x, alpha=0.2):
    win = (1-alpha)**np.arange(x.shape[0])[::-1]
    res = (win*x).sum()/win.sum()
    return res

s.expanding().apply(ewm_func)

# 作为滑动窗口的 ewm 窗口
s.rolling(window=4).apply(ewm_func)
```



#### 数据读取与写入

##### 1. 文件

```python
import pandas as pd

# -- 读
pd.read_csv
pd.read_table  # txt 文件
pd.read_excel

# -- 写
df.to_csv
df.to_table
df.to_excel
```

常用参数（read）：

1. `headers` 

   ```
   int, list of int, default 0
       Row (0-indexed) to use for the column labels of the parsed
       DataFrame. If a list of integers is passed those row positions will
       be combined into a ``MultiIndex``. Use None if there is no header.
   ```

2. `index_col`

   ```
   int, list of int, default None
       Column (0-indexed) to use as the row labels of the DataFrame.
       Pass None if there is no such column.  If a list is passed,
       those columns will be combined into a ``MultiIndex``.  If a
       subset of data is selected with ``usecols``, index_col
       is based on the subset.
   ```

3. `usecols`

   ```
   读取列的集合，默认读取所有的列
   ```

4. `nrows`

   ```
   读取的数据行数
   ```

常用参数（write）:

1. `index`

   ```
   一般在数据写入中，最常用的操作是把 index 设置为 False ，特别当索引没有特殊意义的时候，这样的行为能把索引在保存的时候去除。
   ```

   

特别的：

1. `sep` 在 `read_table` 方法种使用

   ```
   `sep` 参数用于指定 txt 文件中的分隔符，它是一个正则参数。
   ```

   

##### 2. 数据库

###### mysql

```python
import pymysql
from sqlalchemy import create_engine

host = 'localhost'
port = 3306
database = 'test'
user = 'root'
password = '1234'

# -- 读
conn = pymysql.connect(host=host, port=port, database=database, user=user, password=password)

df = pd.read_sql('SELECT * FROM table_name', conn)


# -- 写
engine = create_engine('mysql+pymysql://%s:%s@%s:%s/%s?charset=utf8' % (user, password, host, port, database))

# pandas 写入数据只支持 sqlalchemy.engine & sqlite3 connection
df.to_sql('new_table', engine, if_exists='append')
```

参数 `if_exists`:

```
if_exists : {'fail', 'replace', 'append'}, default 'fail'
    How to behave if the table already exists.

    * fail: Raise a ValueError.
    * replace: Drop the table before inserting new values.
    * append: Insert new values to the existing table.
```

写入时指定数据类型

```python
from sqlalchemy.types import NVARCHAR, Float, Integer

dtypedict = {
  'str': NVARCHAR(length=255),
  'int': Integer(),
  'float': Float()
}
df.to_sql(name='test', con=con, if_exists='append', index=False, dtype=dtypedict)
```



###### mongodb

使用构造方法将读取的数据转化为 `DataFrame` 对象

```python
import pandas as pd
from pymongo import MongoClient
 
 
client = MongoClient()
collection = client["数据库名"]["集合名"]
data = collection.find()
data = list(data)

df = pd.DataFrame(data)
```

##### 3. 从网页

`pandas`可以直接读取 HTML 中的表格数据。注意该方法依赖`beautifulsoup4`和`html5lib`模块。

```python
# 该方法会自动请求该地址
# 并查找网页的表格标签
pd.read_html('https://book.douban.com')
```

#### 基本数据结构

##### 1. Series

用于存储一维数据
具有序列值 `values`、索引 `index`、存储类型 `dtype`、序列的名字 `name`

```python
s = pd.Series(data=[100, 'a', {'name': 'b'}],
              index=pd.Index(['id', 20, 'third'], name='my_idx'),
              dtype='object',
              name='my_s')
```

##### 2. DataFrame

用于存储二维数据
其构造参数有：

```
data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame
    Dict can contain Series, arrays, constants, or list-like objects

index : Index or array-like
    Index to use for resulting frame. Will default to RangeIndex if
    no indexing information part of input data and no index provided

columns : Index or array-like
    Column labels to use for resulting frame. Will default to
    RangeIndex (0, 1, 2, ..., n) if no column labels are provided

dtype : dtype, default None
    Data type to force. Only a single dtype is allowed. If None, infer

copy : boolean, default False
    Copy data from inputs. Only affects DataFrame / 2d ndarray input
```

示例：

```python
>>> data = [[1, 2], ['a', 'b']]
>>> pd.DataFrame(data, index=['num', 'str'], columns=['one', 'two'])
... 	one	two
... num	1	2
... str	a	b
```

#### 常用函数

##### 1. 汇总函数

```python
df.head(2)  # 返回前 2 行
df.tail(2)  # 返回后 2 行

df.info()  # 返回信息概况
df.describe()  # 返回数值列对应的主要统计量
```

##### 2. 特征统计

```python
df.mean
df.sum

df.median
df.var
df.std

df.max
df.min

df.quantile  # 分位数

df.count  # 非缺失值个数

df.idxmax  # 最大值对应的索引
```

上述方法均可指定参数 `axis` 用于指定对列聚合（`0`）或行聚合（`1`）。

##### 3. 唯一值函数

```python
df['column_name'].unique()  # 返回某列唯一值组成的数组

df['column_name'].nunique()  # 返回某列唯一值的数量

# 多列组合的唯一值
# 参数 keep 可以为：
#	'first' 重复组保留第一次出现的所在行
#   'last'  保留最后一次
#   False  不保留
df[['c1', 'c2', 'c3']].drop_duplicates(['c2', 'c3'], keep='last')

# 同 drop_duplicates 但返回的为布尔值列表
df[['c1', 'c2', 'c3']].duplicated(...)
```

##### 4. 替换函数

```python
# 传入 mapper 替换该列中的值
df['c1'].replace({'x': 1, 'y': 2})
df['c1'].replace(['x', 'y'], [1, 2])

# method 指定替换方法
# 'ffill'  向前替换
# 'bfill'  向后替换
s = pd.Series(['a', 1, 'b', 2, 1, 1, 'a'])
s.replace([1, 2], method='ffill')

# output:
"""
0    a
1    a
2    b
3    b
4    b
5    b
6    a
dtype: object
"""

# where 与 mask，分别在传入条件为 False 和 True 时进行替换
# 如果不指定替换值，替换为 NaN
s = pd.Series([-1, 1.2345, 100, -50])
s.where(s < 0)

# out:
"""
0    -1.0
1     NaN
2     NaN
3   -50.0
dtype: float64
"""

s.round(2)  # 保留小数点两位
s.abs()  # 绝对值
s.clip(0, 2)  # 截断，使返回结果中的所有数值不小于 0 不大于 2
```

##### 5. 排序函数

```python
# 按指定 column 进行排序，默认升序
# 传入 ascending=False 改为降序
df.sort_values('column')  

# 多列排序，在列 1 重复时，保持列 1 为升序，其余降序
df.sort_values(['c1', 'c2'], ascending=[True, False])

# 索引排序
df.sort_index
```

##### 6. apply

得益于传入自定义函数的处理， `apply` 的自由度很高，但这是以性能为代价的。一般而言，使用 `pandas` 的内置函数处理和 `apply` 来处理同一个任务，其速度会相差较多，因此只有在确实存在自定义需求的情境下才考虑使用 `apply` 

